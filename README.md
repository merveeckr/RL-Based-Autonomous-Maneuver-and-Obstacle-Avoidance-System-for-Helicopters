ğŸ“Œ RL-Based Autonomous Maneuver and Obstacle Avoidance System for Helicopters

Bu proje; taktik, askeri ve sivil helikopterler iÃ§in RL (Reinforcement Learning) tabanlÄ±, tamamen otonom bir engel kaÃ§Ä±nma ve manevra sistemi geliÅŸtirmeyi amaÃ§lar. Sistem; sensÃ¶r verilerine dayanarak Ã§evreyi algÄ±lar, PPO algoritmasÄ±yla optimal kontrol komutlarÄ± Ã¼retir ve Ã§eÅŸitli zorluk seviyelerinde gÃ¼venli uÃ§uÅŸ kabiliyeti saÄŸlar.

ğŸš Projenin AmacÄ±

Bu projenin ana hedefi:
Helikopterin Ã§evre koÅŸullarÄ±nÄ± sÃ¼rekli analiz edebilmesi
Engelleri algÄ±layÄ±p gÃ¼venli manevralar oluÅŸturmasÄ±
FarklÄ± rÃ¼zgar, basÄ±nÃ§ ve sensÃ¶r gÃ¼rÃ¼ltÃ¼sÃ¼ durumlarÄ±nda stabil uÃ§abilmesi
RL tabanlÄ± otonom kontrol sistemi Ã¼retmek
AirSim/FlightGear gibi gerÃ§ekÃ§i bir simÃ¼lasyon ortamÄ±nda otonom uÃ§uÅŸ gerÃ§ekleÅŸtirmek

Bu sistem;
âœ” Otonom keÅŸifâ€“gÃ¶zetleme gÃ¶revleri
âœ” Riskli uÃ§uÅŸ bÃ¶lgelerinde insansÄ±z gÃ¶rev yÃ¼rÃ¼tme
âœ” Aramaâ€“kurtarma operasyonlarÄ±
âœ” EÄŸitim ve test simÃ¼lasyonlarÄ±
iÃ§in kullanÄ±labilir.

ğŸ§  KullanÄ±lan YÃ¶ntemler ve Teknolojiler
Bu Ã§alÄ±ÅŸmada RL yaklaÅŸÄ±mÄ±yla PPO (Proximal Policy Optimization) kullanÄ±lmÄ±ÅŸtÄ±r.
Teknik kavramlar:
Reinforcement Learning + PPO
Domain Randomization
Curriculum Learning
Continuous Action Space Control
Sensor Noise Modeling
Wind / Turbulence Simulation
Reward Shaping

ğŸ›°ï¸ Sistem Mimarisi
Proje 4 ana katmandan oluÅŸur:

1) Perception Layer
IMU sensÃ¶rÃ¼ (gÃ¼rÃ¼ltÃ¼lÃ¼ veri)
Pozisyon, hÄ±z, yÃ¶nelim verisi
RÃ¼zgar ve Ã§evresel modeller

2) Simulation Layer
AirSim / FlightGear helikopter modeli
Ã‡evresel faktÃ¶rlerin rastgeleleÅŸtirilmesi
Obstacle ve terrain senaryolarÄ±

4) RL Environment (Gym Wrapper)
GÃ¶zlem vektÃ¶rÃ¼ oluÅŸturma
Aksiyon dÃ¶nÃ¼ÅŸÃ¼mlarÄ±
Reward fonksiyonu
Episode baÅŸlangÄ±Ã§/bitiÅŸ ÅŸartlarÄ±
State normalization

5) Control Layer
PPO agent
Actorâ€“Critic mimarisi
Checkpoint, evaluation, loglama
